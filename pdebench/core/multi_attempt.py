"""
å¤šè½®è¿­ä»£æ¨¡å— - ç”¨äºå®éªŒ 2.1

å…è®¸ Agent çœ‹åˆ°é”™è¯¯åè¿›è¡Œå¤šæ¬¡å°è¯•ã€‚
"""

import json
from pathlib import Path
from typing import Dict, Any, Optional, Callable
from .feedback_prompt import create_feedback_prompt


def run_with_attempts(
    original_prompt: str,
    context: Dict[str, Any],
    target_error: float,
    target_time: float,
    oracle_info: Dict[str, Any],
    agent_call_fn: Callable,
    execute_fn: Callable,
    compute_error_fn: Callable,
    max_attempts: int = 3,
    output_dir: Optional[Path] = None
) -> Dict[str, Any]:
    """
    è¿è¡Œå¤šè½®è¿­ä»£
    
    Args:
        original_prompt: åŸå§‹ä»»åŠ¡ prompt
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        target_error: ç›®æ ‡è¯¯å·®
        target_time: ç›®æ ‡æ—¶é—´
        oracle_info: Oracle åŸºå‡†ä¿¡æ¯
        agent_call_fn: è°ƒç”¨ Agent çš„å‡½æ•° (prompt, context) -> response
        execute_fn: æ‰§è¡Œä»£ç çš„å‡½æ•° (code, context) -> exec_result
        compute_error_fn: è®¡ç®—è¯¯å·®çš„å‡½æ•° (output) -> error
        max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
        output_dir: è¾“å‡ºç›®å½•ï¼ˆä¿å­˜ä¸­é—´ç»“æœï¼‰
    
    Returns:
        åŒ…å«æ‰€æœ‰å°è¯•å†å²çš„ç»“æœå­—å…¸
    """
    
    attempts_history = []
    final_result = None
    
    for attempt_num in range(1, max_attempts + 1):
        print(f"\n   ğŸ”„ Attempt {attempt_num}/{max_attempts}...")
        
        # å‡†å¤‡ prompt
        if attempt_num == 1:
            prompt_to_use = original_prompt
        else:
            # æ„å»ºåé¦ˆ prompt
            previous_attempt = attempts_history[-1]
            prompt_to_use = create_feedback_prompt(
                original_prompt=original_prompt,
                previous_attempt=previous_attempt,
                target_error=target_error,
                target_time=target_time,
                oracle_info=oracle_info,
                attempt_num=attempt_num
            )
            
            # ä¿å­˜åé¦ˆ prompt
            if output_dir:
                feedback_prompt_path = output_dir / f"feedback_prompt_attempt_{attempt_num}.md"
                feedback_prompt_path.write_text(prompt_to_use)
        
        # è°ƒç”¨ Agent
        try:
            response = agent_call_fn(prompt_to_use, context)
            
            if not response.success:
                # Agent è°ƒç”¨å¤±è´¥
                attempt_record = {
                    'attempt_num': attempt_num,
                    'code': '',
                    'success': False,
                    'error': None,
                    'time': None,
                    'error_message': response.error,
                    'stderr': '',
                    'status': 'AGENT_ERROR',
                    'llm_usage': response.usage if hasattr(response, 'usage') else {}
                }
                attempts_history.append(attempt_record)
                print(f"   âŒ Agent call failed: {response.error}")
                
                # Agent è°ƒç”¨å¤±è´¥ï¼Œä¸ç»§ç»­å°è¯•
                break
            
            code = response.code
            
            # ä¿å­˜ä»£ç 
            if output_dir:
                code_path = output_dir / f"solver_attempt_{attempt_num}.py"
                code_path.write_text(code)
            
            # æ‰§è¡Œä»£ç 
            exec_result = execute_fn(code, context)
            
            # è®¡ç®—è¯¯å·®ï¼ˆå¦‚æœæ‰§è¡ŒæˆåŠŸï¼‰
            error = None
            if exec_result['success']:
                try:
                    error = compute_error_fn(exec_result['agent_output'])
                except Exception as e:
                    exec_result['success'] = False
                    exec_result['error_message'] = f"Error computation failed: {e}"
            
            # åˆ¤å®šçŠ¶æ€
            if not exec_result['success']:
                status = 'EXECUTION_ERROR'
                fail_reason = exec_result.get('error_message', 'Unknown')
            elif error is None or error != error:  # NaN check
                status = 'EVALUATION_ERROR'
                fail_reason = 'Error computation failed'
            elif error > target_error:
                status = 'ACCURACY_FAIL'
                fail_reason = f"error={error:.2e} > target={target_error:.2e}"
            elif exec_result['time'] > target_time:
                status = 'TIME_FAIL'
                fail_reason = f"time={exec_result['time']:.3f}s > target={target_time:.3f}s"
            else:
                status = 'PASS'
                fail_reason = None
            
            # è®°å½•æœ¬æ¬¡å°è¯•
            attempt_record = {
                'attempt_num': attempt_num,
                'code': code,
                'success': exec_result['success'],
                'error': error,
                'time': exec_result['time'],
                'error_message': exec_result.get('error_message'),
                'stderr': exec_result.get('stderr'),
                'status': status,
                'fail_reason': fail_reason,
                'llm_usage': response.usage if hasattr(response, 'usage') else {}
            }
            attempts_history.append(attempt_record)
            
            # æ‰“å°ç»“æœ
            if status == 'PASS':
                print(f"   âœ… Passed on attempt {attempt_num}!")
                break
            else:
                print(f"   âŒ {status}: {fail_reason[:80]}")
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•
                if attempt_num == max_attempts:
                    print(f"   âš ï¸  Failed after {max_attempts} attempts")
        
        except Exception as e:
            # æ•è·æ„å¤–é”™è¯¯
            attempt_record = {
                'attempt_num': attempt_num,
                'code': '',
                'success': False,
                'error': None,
                'time': None,
                'error_message': f"Unexpected error: {str(e)}",
                'stderr': '',
                'status': 'UNEXPECTED_ERROR',
                'llm_usage': {}
            }
            attempts_history.append(attempt_record)
            print(f"   âŒ Unexpected error: {e}")
            break
    
    # åˆ†ææ”¹è¿›è½¨è¿¹
    improvement_analysis = analyze_improvement(attempts_history)
    
    # ä¿å­˜å°è¯•å†å²
    if output_dir:
        history_path = output_dir / "attempts_history.json"
        with open(history_path, 'w') as f:
            json.dump({
                'attempts': attempts_history,
                'improvement_analysis': improvement_analysis
            }, f, indent=2)
    
    # æ„å»ºæœ€ç»ˆç»“æœ
    final_attempt = attempts_history[-1]
    final_result = {
        'final_status': final_attempt['status'],
        'final_error': final_attempt.get('error'),
        'final_time': final_attempt.get('time'),
        'num_attempts': len(attempts_history),
        'attempts_history': attempts_history,
        'improvement_analysis': improvement_analysis,
        'code': final_attempt.get('code', ''),
        'error_message': final_attempt.get('error_message'),
        'stderr': final_attempt.get('stderr'),
        'success': final_attempt.get('success', False),
    }
    
    return final_result


def analyze_improvement(attempts_history: list) -> Dict[str, Any]:
    """
    åˆ†ææ”¹è¿›è½¨è¿¹
    
    Args:
        attempts_history: æ‰€æœ‰å°è¯•çš„åˆ—è¡¨
    
    Returns:
        æ”¹è¿›åˆ†æå­—å…¸
    """
    analysis = {
        'total_attempts': len(attempts_history),
        'final_success': attempts_history[-1]['status'] == 'PASS',
        'improved': False,
        'error_trajectory': [],
        'time_trajectory': [],
        'status_trajectory': []
    }
    
    # æ”¶é›†è½¨è¿¹
    for attempt in attempts_history:
        analysis['status_trajectory'].append(attempt['status'])
        
        if attempt['success'] and attempt['error'] is not None:
            analysis['error_trajectory'].append(attempt['error'])
            analysis['time_trajectory'].append(attempt['time'])
    
    # åˆ¤æ–­æ˜¯å¦æœ‰æ”¹è¿›
    if len(analysis['error_trajectory']) > 1:
        first_error = analysis['error_trajectory'][0]
        last_error = analysis['error_trajectory'][-1]
        
        # è¯¯å·®ä¸‹é™ = æ”¹è¿›
        if last_error < first_error:
            analysis['improved'] = True
            analysis['error_reduction_pct'] = (first_error - last_error) / first_error * 100
        
        # è®°å½•æœ€ä½³è¯¯å·®
        analysis['best_error'] = min(analysis['error_trajectory'])
        analysis['best_error_attempt'] = analysis['error_trajectory'].index(analysis['best_error']) + 1
    
    # ç»Ÿè®¡å„ç±»å¤±è´¥
    failure_counts = {}
    for attempt in attempts_history:
        if attempt['status'] != 'PASS':
            failure_counts[attempt['status']] = failure_counts.get(attempt['status'], 0) + 1
    
    analysis['failure_distribution'] = failure_counts
    
    return analysis
